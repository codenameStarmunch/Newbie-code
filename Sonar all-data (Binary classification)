import numpy
from matplotlib import pyplot
from pandas import set_option
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
import pandas as pd

dataset = pd.read_csv("sonar.all-data", header=None)

print(dataset.head())

print(dataset.shape)

set_option('display.width', 100)
print(dataset.head(20))

set_option("precision", 3)
print(dataset.describe())


fig = pyplot.figure()
ax = fig.add_subplot(111)
cax = ax.matshow(dataset.corr(), vmin=-1, vmax=1, interpolation="none")
fig.colorbar(cax)
pyplot.show()

array = dataset.values
X = array[:, 0:60]
Y = array[:, 60]

X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size = 0.20, random_state = 7)

models = [("LR", LogisticRegression(solver = "liblinear", multi_class = "ovr")), ("LDA", LinearDiscriminantAnalysis()), ("KNN", KNeighborsClassifier()), 
        ("CART", DecisionTreeClassifier()), ("NB", GaussianNB()), ("SVM", SVC(gamma = "auto"))]

results = []
names = []

for name, model in models:
  kfold = KFold(n_splits = 10, random_state = 7, shuffle = True)
  cv_results = cross_val_score(model, X_train, Y_train, cv = kfold, scoring = "accuracy")
  results.append(cv_results)
  names.append(name)

  print(f"{name},  {cv_results.mean()}, {cv_results.std()}")
